{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                              location      age        isbn  rating  \\\nuser_id                                                               \n3329            grantsville, utah, usa  34.7439  0440234743       8   \n7346        sunnyvale, california, usa  49.0000  0440234743       9   \n7352               houston, texas, usa  53.0000  0440234743       8   \n9419             somewhere, texas, usa  34.7439  0440234743       5   \n11224        tumwater, washington, usa  51.0000  0440234743       6   \n...                                ...      ...         ...     ...   \n223566      kansas city, missouri, usa  29.0000  1880418568       8   \n242083       fairview, new mexico, usa  24.0000  1880418568       7   \n245604           napa, california, usa  43.0000  1880418568       9   \n254995      san diego, california, usa  39.0000  1880418568       7   \n259259   woodruff, south carolina, usa  30.0000  1880418568      10   \n\n                                           book_title   book_author  \\\nuser_id                                                               \n3329                                    The Testament  John Grisham   \n7346                                    The Testament  John Grisham   \n7352                                    The Testament  John Grisham   \n9419                                    The Testament  John Grisham   \n11224                                   The Testament  John Grisham   \n...                                               ...           ...   \n223566   Wolves of the Calla (The Dark Tower, Book 5)  Stephen King   \n242083   Wolves of the Calla (The Dark Tower, Book 5)  Stephen King   \n245604   Wolves of the Calla (The Dark Tower, Book 5)  Stephen King   \n254995   Wolves of the Calla (The Dark Tower, Book 5)  Stephen King   \n259259   Wolves of the Calla (The Dark Tower, Book 5)  Stephen King   \n\n         year_of_publication                 publisher  \\\nuser_id                                                  \n3329                  1999.0                      Dell   \n7346                  1999.0                      Dell   \n7352                  1999.0                      Dell   \n9419                  1999.0                      Dell   \n11224                 1999.0                      Dell   \n...                      ...                       ...   \n223566                2003.0  Donald M. Grant/Scribner   \n242083                2003.0  Donald M. Grant/Scribner   \n245604                2003.0  Donald M. Grant/Scribner   \n254995                2003.0  Donald M. Grant/Scribner   \n259259                2003.0  Donald M. Grant/Scribner   \n\n                                                     img_s  \\\nuser_id                                                      \n3329     http://images.amazon.com/images/P/0440234743.0...   \n7346     http://images.amazon.com/images/P/0440234743.0...   \n7352     http://images.amazon.com/images/P/0440234743.0...   \n9419     http://images.amazon.com/images/P/0440234743.0...   \n11224    http://images.amazon.com/images/P/0440234743.0...   \n...                                                    ...   \n223566   http://images.amazon.com/images/P/1880418568.0...   \n242083   http://images.amazon.com/images/P/1880418568.0...   \n245604   http://images.amazon.com/images/P/1880418568.0...   \n254995   http://images.amazon.com/images/P/1880418568.0...   \n259259   http://images.amazon.com/images/P/1880418568.0...   \n\n                                                     img_m  \\\nuser_id                                                      \n3329     http://images.amazon.com/images/P/0440234743.0...   \n7346     http://images.amazon.com/images/P/0440234743.0...   \n7352     http://images.amazon.com/images/P/0440234743.0...   \n9419     http://images.amazon.com/images/P/0440234743.0...   \n11224    http://images.amazon.com/images/P/0440234743.0...   \n...                                                    ...   \n223566   http://images.amazon.com/images/P/1880418568.0...   \n242083   http://images.amazon.com/images/P/1880418568.0...   \n245604   http://images.amazon.com/images/P/1880418568.0...   \n254995   http://images.amazon.com/images/P/1880418568.0...   \n259259   http://images.amazon.com/images/P/1880418568.0...   \n\n                                                     img_l  \\\nuser_id                                                      \n3329     http://images.amazon.com/images/P/0440234743.0...   \n7346     http://images.amazon.com/images/P/0440234743.0...   \n7352     http://images.amazon.com/images/P/0440234743.0...   \n9419     http://images.amazon.com/images/P/0440234743.0...   \n11224    http://images.amazon.com/images/P/0440234743.0...   \n...                                                    ...   \n223566   http://images.amazon.com/images/P/1880418568.0...   \n242083   http://images.amazon.com/images/P/1880418568.0...   \n245604   http://images.amazon.com/images/P/1880418568.0...   \n254995   http://images.amazon.com/images/P/1880418568.0...   \n259259   http://images.amazon.com/images/P/1880418568.0...   \n\n                                                   Summary Language  \\\nuser_id                                                               \n3329     A suicidal billionaire, a burnt-out Washington...       en   \n7346     A suicidal billionaire, a burnt-out Washington...       en   \n7352     A suicidal billionaire, a burnt-out Washington...       en   \n9419     A suicidal billionaire, a burnt-out Washington...       en   \n11224    A suicidal billionaire, a burnt-out Washington...       en   \n...                                                    ...      ...   \n223566   Along with his companions, gunslinger Roland e...       en   \n242083   Along with his companions, gunslinger Roland e...       en   \n245604   Along with his companions, gunslinger Roland e...       en   \n254995   Along with his companions, gunslinger Roland e...       en   \n259259   Along with his companions, gunslinger Roland e...       en   \n\n            Category         city           state country  \nuser_id                                                    \n3329     ['Fiction']  grantsville            utah     usa  \n7346     ['Fiction']    sunnyvale      california     usa  \n7352     ['Fiction']      houston           texas     usa  \n9419     ['Fiction']    somewhere           texas     usa  \n11224    ['Fiction']     tumwater      washington     usa  \n...              ...          ...             ...     ...  \n223566   ['Fiction']  kansas city        missouri     usa  \n242083   ['Fiction']     fairview      new mexico     usa  \n245604   ['Fiction']         napa      california     usa  \n254995   ['Fiction']    san diego      california     usa  \n259259   ['Fiction']     woodruff  south carolina     usa  \n\n[95580 rows x 17 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location</th>\n      <th>age</th>\n      <th>isbn</th>\n      <th>rating</th>\n      <th>book_title</th>\n      <th>book_author</th>\n      <th>year_of_publication</th>\n      <th>publisher</th>\n      <th>img_s</th>\n      <th>img_m</th>\n      <th>img_l</th>\n      <th>Summary</th>\n      <th>Language</th>\n      <th>Category</th>\n      <th>city</th>\n      <th>state</th>\n      <th>country</th>\n    </tr>\n    <tr>\n      <th>user_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3329</th>\n      <td>grantsville, utah, usa</td>\n      <td>34.7439</td>\n      <td>0440234743</td>\n      <td>8</td>\n      <td>The Testament</td>\n      <td>John Grisham</td>\n      <td>1999.0</td>\n      <td>Dell</td>\n      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n      <td>A suicidal billionaire, a burnt-out Washington...</td>\n      <td>en</td>\n      <td>['Fiction']</td>\n      <td>grantsville</td>\n      <td>utah</td>\n      <td>usa</td>\n    </tr>\n    <tr>\n      <th>7346</th>\n      <td>sunnyvale, california, usa</td>\n      <td>49.0000</td>\n      <td>0440234743</td>\n      <td>9</td>\n      <td>The Testament</td>\n      <td>John Grisham</td>\n      <td>1999.0</td>\n      <td>Dell</td>\n      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n      <td>A suicidal billionaire, a burnt-out Washington...</td>\n      <td>en</td>\n      <td>['Fiction']</td>\n      <td>sunnyvale</td>\n      <td>california</td>\n      <td>usa</td>\n    </tr>\n    <tr>\n      <th>7352</th>\n      <td>houston, texas, usa</td>\n      <td>53.0000</td>\n      <td>0440234743</td>\n      <td>8</td>\n      <td>The Testament</td>\n      <td>John Grisham</td>\n      <td>1999.0</td>\n      <td>Dell</td>\n      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n      <td>A suicidal billionaire, a burnt-out Washington...</td>\n      <td>en</td>\n      <td>['Fiction']</td>\n      <td>houston</td>\n      <td>texas</td>\n      <td>usa</td>\n    </tr>\n    <tr>\n      <th>9419</th>\n      <td>somewhere, texas, usa</td>\n      <td>34.7439</td>\n      <td>0440234743</td>\n      <td>5</td>\n      <td>The Testament</td>\n      <td>John Grisham</td>\n      <td>1999.0</td>\n      <td>Dell</td>\n      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n      <td>A suicidal billionaire, a burnt-out Washington...</td>\n      <td>en</td>\n      <td>['Fiction']</td>\n      <td>somewhere</td>\n      <td>texas</td>\n      <td>usa</td>\n    </tr>\n    <tr>\n      <th>11224</th>\n      <td>tumwater, washington, usa</td>\n      <td>51.0000</td>\n      <td>0440234743</td>\n      <td>6</td>\n      <td>The Testament</td>\n      <td>John Grisham</td>\n      <td>1999.0</td>\n      <td>Dell</td>\n      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n      <td>http://images.amazon.com/images/P/0440234743.0...</td>\n      <td>A suicidal billionaire, a burnt-out Washington...</td>\n      <td>en</td>\n      <td>['Fiction']</td>\n      <td>tumwater</td>\n      <td>washington</td>\n      <td>usa</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>223566</th>\n      <td>kansas city, missouri, usa</td>\n      <td>29.0000</td>\n      <td>1880418568</td>\n      <td>8</td>\n      <td>Wolves of the Calla (The Dark Tower, Book 5)</td>\n      <td>Stephen King</td>\n      <td>2003.0</td>\n      <td>Donald M. Grant/Scribner</td>\n      <td>http://images.amazon.com/images/P/1880418568.0...</td>\n      <td>http://images.amazon.com/images/P/1880418568.0...</td>\n      <td>http://images.amazon.com/images/P/1880418568.0...</td>\n      <td>Along with his companions, gunslinger Roland e...</td>\n      <td>en</td>\n      <td>['Fiction']</td>\n      <td>kansas city</td>\n      <td>missouri</td>\n      <td>usa</td>\n    </tr>\n    <tr>\n      <th>242083</th>\n      <td>fairview, new mexico, usa</td>\n      <td>24.0000</td>\n      <td>1880418568</td>\n      <td>7</td>\n      <td>Wolves of the Calla (The Dark Tower, Book 5)</td>\n      <td>Stephen King</td>\n      <td>2003.0</td>\n      <td>Donald M. Grant/Scribner</td>\n      <td>http://images.amazon.com/images/P/1880418568.0...</td>\n      <td>http://images.amazon.com/images/P/1880418568.0...</td>\n      <td>http://images.amazon.com/images/P/1880418568.0...</td>\n      <td>Along with his companions, gunslinger Roland e...</td>\n      <td>en</td>\n      <td>['Fiction']</td>\n      <td>fairview</td>\n      <td>new mexico</td>\n      <td>usa</td>\n    </tr>\n    <tr>\n      <th>245604</th>\n      <td>napa, california, usa</td>\n      <td>43.0000</td>\n      <td>1880418568</td>\n      <td>9</td>\n      <td>Wolves of the Calla (The Dark Tower, Book 5)</td>\n      <td>Stephen King</td>\n      <td>2003.0</td>\n      <td>Donald M. Grant/Scribner</td>\n      <td>http://images.amazon.com/images/P/1880418568.0...</td>\n      <td>http://images.amazon.com/images/P/1880418568.0...</td>\n      <td>http://images.amazon.com/images/P/1880418568.0...</td>\n      <td>Along with his companions, gunslinger Roland e...</td>\n      <td>en</td>\n      <td>['Fiction']</td>\n      <td>napa</td>\n      <td>california</td>\n      <td>usa</td>\n    </tr>\n    <tr>\n      <th>254995</th>\n      <td>san diego, california, usa</td>\n      <td>39.0000</td>\n      <td>1880418568</td>\n      <td>7</td>\n      <td>Wolves of the Calla (The Dark Tower, Book 5)</td>\n      <td>Stephen King</td>\n      <td>2003.0</td>\n      <td>Donald M. Grant/Scribner</td>\n      <td>http://images.amazon.com/images/P/1880418568.0...</td>\n      <td>http://images.amazon.com/images/P/1880418568.0...</td>\n      <td>http://images.amazon.com/images/P/1880418568.0...</td>\n      <td>Along with his companions, gunslinger Roland e...</td>\n      <td>en</td>\n      <td>['Fiction']</td>\n      <td>san diego</td>\n      <td>california</td>\n      <td>usa</td>\n    </tr>\n    <tr>\n      <th>259259</th>\n      <td>woodruff, south carolina, usa</td>\n      <td>30.0000</td>\n      <td>1880418568</td>\n      <td>10</td>\n      <td>Wolves of the Calla (The Dark Tower, Book 5)</td>\n      <td>Stephen King</td>\n      <td>2003.0</td>\n      <td>Donald M. Grant/Scribner</td>\n      <td>http://images.amazon.com/images/P/1880418568.0...</td>\n      <td>http://images.amazon.com/images/P/1880418568.0...</td>\n      <td>http://images.amazon.com/images/P/1880418568.0...</td>\n      <td>Along with his companions, gunslinger Roland e...</td>\n      <td>en</td>\n      <td>['Fiction']</td>\n      <td>woodruff</td>\n      <td>south carolina</td>\n      <td>usa</td>\n    </tr>\n  </tbody>\n</table>\n<p>95580 rows Ã— 17 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/processed/preprocessed-data.csv', index_col=0, encoding = 'ISO-8859-1')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users   = pd.read_csv('../data/raw/BX-Users.csv', delimiter = \";\",encoding = 'ISO-8859-1', names=['user_id','location','age'], skiprows=1)\n",
    "books   = pd.read_csv('../data/raw/BX_Books.csv', delimiter = \";\",encoding = 'ISO-8859-1', names=['isbn','book_title','book_author','year_of_publication', 'publisher', 'img_s', 'img_m', 'img_l'], skiprows=1)\n",
    "ratings = pd.read_csv('../data/raw/BX-Book-Ratings.csv', delimiter = \";\",encoding = 'ISO-8859-1',names=['user_id','isbn','rating'], skiprows=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing and Exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id                   location      age        isbn  rating  \\\n0        2  stockton, california, usa  18.0000  0195153448       0   \n1        8   timmins, ontario, canada  34.7439  0002005018       5   \n2    11400    ottawa, ontario, canada  49.0000  0002005018       0   \n3    11676              n/a, n/a, n/a  34.7439  0002005018       8   \n4    41385   sudbury, ontario, canada  34.7439  0002005018       0   \n\n            book_title           book_author  year_of_publication  \\\n0  Classical Mythology    Mark P. O. Morford               2002.0   \n1         Clara Callan  Richard Bruce Wright               2001.0   \n2         Clara Callan  Richard Bruce Wright               2001.0   \n3         Clara Callan  Richard Bruce Wright               2001.0   \n4         Clara Callan  Richard Bruce Wright               2001.0   \n\n                 publisher                                              img_s  \\\n0  Oxford University Press  http://images.amazon.com/images/P/0195153448.0...   \n1    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n2    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n3    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n4    HarperFlamingo Canada  http://images.amazon.com/images/P/0002005018.0...   \n\n                                               img_m  \\\n0  http://images.amazon.com/images/P/0195153448.0...   \n1  http://images.amazon.com/images/P/0002005018.0...   \n2  http://images.amazon.com/images/P/0002005018.0...   \n3  http://images.amazon.com/images/P/0002005018.0...   \n4  http://images.amazon.com/images/P/0002005018.0...   \n\n                                               img_l  \\\n0  http://images.amazon.com/images/P/0195153448.0...   \n1  http://images.amazon.com/images/P/0002005018.0...   \n2  http://images.amazon.com/images/P/0002005018.0...   \n3  http://images.amazon.com/images/P/0002005018.0...   \n4  http://images.amazon.com/images/P/0002005018.0...   \n\n                                             Summary Language  \\\n0  Provides an introduction to classical myths pl...       en   \n1  In a small town in Canada, Clara Callan reluct...       en   \n2  In a small town in Canada, Clara Callan reluct...       en   \n3  In a small town in Canada, Clara Callan reluct...       en   \n4  In a small town in Canada, Clara Callan reluct...       en   \n\n             Category      city       state country  \n0  ['Social Science']  stockton  california     usa  \n1       ['Actresses']   timmins     ontario  canada  \n2       ['Actresses']    ottawa     ontario  canada  \n3       ['Actresses']       NaN         NaN     NaN  \n4       ['Actresses']   sudbury     ontario  canada  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>location</th>\n      <th>age</th>\n      <th>isbn</th>\n      <th>rating</th>\n      <th>book_title</th>\n      <th>book_author</th>\n      <th>year_of_publication</th>\n      <th>publisher</th>\n      <th>img_s</th>\n      <th>img_m</th>\n      <th>img_l</th>\n      <th>Summary</th>\n      <th>Language</th>\n      <th>Category</th>\n      <th>city</th>\n      <th>state</th>\n      <th>country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>stockton, california, usa</td>\n      <td>18.0000</td>\n      <td>0195153448</td>\n      <td>0</td>\n      <td>Classical Mythology</td>\n      <td>Mark P. O. Morford</td>\n      <td>2002.0</td>\n      <td>Oxford University Press</td>\n      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n      <td>Provides an introduction to classical myths pl...</td>\n      <td>en</td>\n      <td>['Social Science']</td>\n      <td>stockton</td>\n      <td>california</td>\n      <td>usa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>timmins, ontario, canada</td>\n      <td>34.7439</td>\n      <td>0002005018</td>\n      <td>5</td>\n      <td>Clara Callan</td>\n      <td>Richard Bruce Wright</td>\n      <td>2001.0</td>\n      <td>HarperFlamingo Canada</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n      <td>In a small town in Canada, Clara Callan reluct...</td>\n      <td>en</td>\n      <td>['Actresses']</td>\n      <td>timmins</td>\n      <td>ontario</td>\n      <td>canada</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11400</td>\n      <td>ottawa, ontario, canada</td>\n      <td>49.0000</td>\n      <td>0002005018</td>\n      <td>0</td>\n      <td>Clara Callan</td>\n      <td>Richard Bruce Wright</td>\n      <td>2001.0</td>\n      <td>HarperFlamingo Canada</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n      <td>In a small town in Canada, Clara Callan reluct...</td>\n      <td>en</td>\n      <td>['Actresses']</td>\n      <td>ottawa</td>\n      <td>ontario</td>\n      <td>canada</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11676</td>\n      <td>n/a, n/a, n/a</td>\n      <td>34.7439</td>\n      <td>0002005018</td>\n      <td>8</td>\n      <td>Clara Callan</td>\n      <td>Richard Bruce Wright</td>\n      <td>2001.0</td>\n      <td>HarperFlamingo Canada</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n      <td>In a small town in Canada, Clara Callan reluct...</td>\n      <td>en</td>\n      <td>['Actresses']</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>41385</td>\n      <td>sudbury, ontario, canada</td>\n      <td>34.7439</td>\n      <td>0002005018</td>\n      <td>0</td>\n      <td>Clara Callan</td>\n      <td>Richard Bruce Wright</td>\n      <td>2001.0</td>\n      <td>HarperFlamingo Canada</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n      <td>In a small town in Canada, Clara Callan reluct...</td>\n      <td>en</td>\n      <td>['Actresses']</td>\n      <td>sudbury</td>\n      <td>ontario</td>\n      <td>canada</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1031175, 18)\n"
     ]
    }
   ],
   "source": [
    "display(df.head())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id                            location   age\n0        1                  nyc, new york, usa   NaN\n1        2           stockton, california, usa  18.0\n2        3     moscow, yukon territory, russia   NaN\n3        4           porto, v.n.gaia, portugal  17.0\n4        5  farnborough, hants, united kingdom   NaN",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>location</th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>nyc, new york, usa</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>stockton, california, usa</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>moscow, yukon territory, russia</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>porto, v.n.gaia, portugal</td>\n      <td>17.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>farnborough, hants, united kingdom</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "         isbn                                         book_title  \\\n0  0195153448                                Classical Mythology   \n1  0002005018                                       Clara Callan   \n2  0060973129                               Decision in Normandy   \n3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n4  0393045218                             The Mummies of Urumchi   \n\n            book_author  year_of_publication                publisher  \\\n0    Mark P. O. Morford                 2002  Oxford University Press   \n1  Richard Bruce Wright                 2001    HarperFlamingo Canada   \n2          Carlo D'Este                 1991          HarperPerennial   \n3      Gina Bari Kolata                 1999     Farrar Straus Giroux   \n4       E. J. W. Barber                 1999   W. W. Norton & Company   \n\n                                               img_s  \\\n0  http://images.amazon.com/images/P/0195153448.0...   \n1  http://images.amazon.com/images/P/0002005018.0...   \n2  http://images.amazon.com/images/P/0060973129.0...   \n3  http://images.amazon.com/images/P/0374157065.0...   \n4  http://images.amazon.com/images/P/0393045218.0...   \n\n                                               img_m  \\\n0  http://images.amazon.com/images/P/0195153448.0...   \n1  http://images.amazon.com/images/P/0002005018.0...   \n2  http://images.amazon.com/images/P/0060973129.0...   \n3  http://images.amazon.com/images/P/0374157065.0...   \n4  http://images.amazon.com/images/P/0393045218.0...   \n\n                                               img_l  \n0  http://images.amazon.com/images/P/0195153448.0...  \n1  http://images.amazon.com/images/P/0002005018.0...  \n2  http://images.amazon.com/images/P/0060973129.0...  \n3  http://images.amazon.com/images/P/0374157065.0...  \n4  http://images.amazon.com/images/P/0393045218.0...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isbn</th>\n      <th>book_title</th>\n      <th>book_author</th>\n      <th>year_of_publication</th>\n      <th>publisher</th>\n      <th>img_s</th>\n      <th>img_m</th>\n      <th>img_l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0195153448</td>\n      <td>Classical Mythology</td>\n      <td>Mark P. O. Morford</td>\n      <td>2002</td>\n      <td>Oxford University Press</td>\n      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002005018</td>\n      <td>Clara Callan</td>\n      <td>Richard Bruce Wright</td>\n      <td>2001</td>\n      <td>HarperFlamingo Canada</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0060973129</td>\n      <td>Decision in Normandy</td>\n      <td>Carlo D'Este</td>\n      <td>1991</td>\n      <td>HarperPerennial</td>\n      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0374157065</td>\n      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n      <td>Gina Bari Kolata</td>\n      <td>1999</td>\n      <td>Farrar Straus Giroux</td>\n      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0393045218</td>\n      <td>The Mummies of Urumchi</td>\n      <td>E. J. W. Barber</td>\n      <td>1999</td>\n      <td>W. W. Norton &amp; Company</td>\n      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(271379, 8)\n"
     ]
    }
   ],
   "source": [
    "display(books.head())\n",
    "print(books.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id        isbn  rating\n0   276725  034545104X       0\n1   276726  0155061224       5\n2   276727  0446520802       0\n3   276729  052165615X       3\n4   276729  0521795028       6",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>isbn</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>276725</td>\n      <td>034545104X</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>276726</td>\n      <td>0155061224</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>276727</td>\n      <td>0446520802</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>276729</td>\n      <td>052165615X</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>276729</td>\n      <td>0521795028</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1149780, 3)\n"
     ]
    }
   ],
   "source": [
    "display(ratings.head())\n",
    "print(ratings.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the shape of the two data frames `df` (`1,031,175 rows`), which is the preprocessed one, and `ratings` (`1,149,780 rows`) we see a discrepancy of `118,605` ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id        isbn  rating                       location   age\n0   276725  034545104X       0              tyler, texas, usa   NaN\n1   276726  0155061224       5       seattle, washington, usa   NaN\n2   276727  0446520802       0  h, new south wales, australia  16.0\n3   276729  052165615X       3           rijeka, n/a, croatia  16.0\n4   276729  0521795028       6           rijeka, n/a, croatia  16.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>isbn</th>\n      <th>rating</th>\n      <th>location</th>\n      <th>age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>276725</td>\n      <td>034545104X</td>\n      <td>0</td>\n      <td>tyler, texas, usa</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>276726</td>\n      <td>0155061224</td>\n      <td>5</td>\n      <td>seattle, washington, usa</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>276727</td>\n      <td>0446520802</td>\n      <td>0</td>\n      <td>h, new south wales, australia</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>276729</td>\n      <td>052165615X</td>\n      <td>3</td>\n      <td>rijeka, n/a, croatia</td>\n      <td>16.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>276729</td>\n      <td>0521795028</td>\n      <td>6</td>\n      <td>rijeka, n/a, croatia</td>\n      <td>16.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1149780, 5)\n"
     ]
    }
   ],
   "source": [
    "combined = pd.merge(ratings, users, on='user_id', how='inner')\n",
    "\n",
    "display(combined.head())\n",
    "print(combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merging the original `ratings` dataframe on the `users` datafram with an inner join (i.e. keeping those rows where the key is in both dataframes), we see that the number of ratings does not change. Thus, all users in the `ratings` dataframe are covered in the `users` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   user_id        isbn  rating            book_title book_author  \\\n0   276725  034545104X       0  Flesh Tones: A Novel  M. J. Rose   \n1     2313  034545104X       5  Flesh Tones: A Novel  M. J. Rose   \n2     6543  034545104X       0  Flesh Tones: A Novel  M. J. Rose   \n3     8680  034545104X       5  Flesh Tones: A Novel  M. J. Rose   \n4    10314  034545104X       9  Flesh Tones: A Novel  M. J. Rose   \n\n   year_of_publication         publisher  \\\n0                 2002  Ballantine Books   \n1                 2002  Ballantine Books   \n2                 2002  Ballantine Books   \n3                 2002  Ballantine Books   \n4                 2002  Ballantine Books   \n\n                                               img_s  \\\n0  http://images.amazon.com/images/P/034545104X.0...   \n1  http://images.amazon.com/images/P/034545104X.0...   \n2  http://images.amazon.com/images/P/034545104X.0...   \n3  http://images.amazon.com/images/P/034545104X.0...   \n4  http://images.amazon.com/images/P/034545104X.0...   \n\n                                               img_m  \\\n0  http://images.amazon.com/images/P/034545104X.0...   \n1  http://images.amazon.com/images/P/034545104X.0...   \n2  http://images.amazon.com/images/P/034545104X.0...   \n3  http://images.amazon.com/images/P/034545104X.0...   \n4  http://images.amazon.com/images/P/034545104X.0...   \n\n                                               img_l  \n0  http://images.amazon.com/images/P/034545104X.0...  \n1  http://images.amazon.com/images/P/034545104X.0...  \n2  http://images.amazon.com/images/P/034545104X.0...  \n3  http://images.amazon.com/images/P/034545104X.0...  \n4  http://images.amazon.com/images/P/034545104X.0...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user_id</th>\n      <th>isbn</th>\n      <th>rating</th>\n      <th>book_title</th>\n      <th>book_author</th>\n      <th>year_of_publication</th>\n      <th>publisher</th>\n      <th>img_s</th>\n      <th>img_m</th>\n      <th>img_l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>276725</td>\n      <td>034545104X</td>\n      <td>0</td>\n      <td>Flesh Tones: A Novel</td>\n      <td>M. J. Rose</td>\n      <td>2002</td>\n      <td>Ballantine Books</td>\n      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2313</td>\n      <td>034545104X</td>\n      <td>5</td>\n      <td>Flesh Tones: A Novel</td>\n      <td>M. J. Rose</td>\n      <td>2002</td>\n      <td>Ballantine Books</td>\n      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6543</td>\n      <td>034545104X</td>\n      <td>0</td>\n      <td>Flesh Tones: A Novel</td>\n      <td>M. J. Rose</td>\n      <td>2002</td>\n      <td>Ballantine Books</td>\n      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8680</td>\n      <td>034545104X</td>\n      <td>5</td>\n      <td>Flesh Tones: A Novel</td>\n      <td>M. J. Rose</td>\n      <td>2002</td>\n      <td>Ballantine Books</td>\n      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10314</td>\n      <td>034545104X</td>\n      <td>9</td>\n      <td>Flesh Tones: A Novel</td>\n      <td>M. J. Rose</td>\n      <td>2002</td>\n      <td>Ballantine Books</td>\n      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1031175, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "display(combined.head())\n",
    "print(combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "applying the same for `ratings` and `books` dataframes we see how the discrepancy between `ratings` and the preprocessed dataframe `df` occur.\n",
    "\n",
    "It seems that the `books` dataframe has some `ISBN`s missing. Thus, ratings where there is no match on the `books` dataframe are dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the `df` dataframe from the `Preprocessed_data.csv` file is valid. For further exploration the `df` dataframe is used as it also has the three features `Summary`, `Language`, and `Category`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to have a not so sparse dataframe we do want to only consider the following ratings:\n",
    "- ratings where the rating is between 1 and 10 (only explicit ratings, no 0 rating)\n",
    "- books that have been rated at least by 20 different users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function printing the number of unique users and books in the dataframe\n",
    "def print_information(df, name):\n",
    "    df_num_ratings =  df.shape[0]\n",
    "    df_num_users = len(df['user_id'].unique())\n",
    "    df_num_books = len(df['isbn'].unique())\n",
    "    print(f'For {name}:\\n\\tNumber of unique users: {df_num_users}\\n\\tNumber of unique books: {df_num_books}\\n\\tNumber of ratings: {df_num_ratings}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For original data frame:\n",
      "\tNumber of unique users: 92107\n",
      "\tNumber of unique books: 270170\n",
      "\tNumber of ratings: 1031175\n"
     ]
    }
   ],
   "source": [
    "#Information about the dataframe before preprocessing\n",
    "print_information(df, 'original data frame')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For dataframe only books rated with 1 or higher (i.e. no 0 ratings):\n",
      "\tNumber of unique users: 68092\n",
      "\tNumber of unique books: 149842\n",
      "\tNumber of ratings: 383852\n"
     ]
    },
    {
     "data": {
      "text/plain": "1      1481\n2      2375\n3      5118\n4      7617\n6     31689\n5     45355\n9     60780\n7     66404\n10    71227\n8     91806\nName: rating, dtype: int64"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only taking rating between 1 and 10\n",
    "df_no_zeros = df.loc[df['rating'] > 0]\n",
    "print_information(df_no_zeros, 'dataframe only books rated with 1 or higher (i.e. no 0 ratings)')\n",
    "df_no_zeros['rating'].value_counts().sort_values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For dataframe only books rated more than 10 times:\n",
      "\tNumber of unique users: 39365\n",
      "\tNumber of unique books: 5444\n",
      "\tNumber of ratings: 139296\n",
      "For dataframe only books rated more than 15 times:\n",
      "\tNumber of unique users: 34573\n",
      "\tNumber of unique books: 3151\n",
      "\tNumber of ratings: 112631\n",
      "For dataframe only books rated more than 20 times:\n",
      "\tNumber of unique users: 31383\n",
      "\tNumber of unique books: 2129\n",
      "\tNumber of ratings: 95580\n"
     ]
    }
   ],
   "source": [
    "#only taking ratings of books where the book was rated at least 20 times\n",
    "df_10_ratings_least = df_no_zeros.groupby('isbn').filter(lambda df: df.shape[0] > 9)\n",
    "print_information(df_10_ratings_least, 'dataframe only books rated more than 10 times')\n",
    "\n",
    "#only taking ratings of books where the book was rated at least 20 times\n",
    "df_15_ratings_least = df_no_zeros.groupby('isbn').filter(lambda df: df.shape[0] > 14)\n",
    "print_information(df_15_ratings_least, 'dataframe only books rated more than 15 times')\n",
    "\n",
    "#only taking ratings of books where the book was rated at least 20 times\n",
    "df_20_ratings_least = df_no_zeros.groupby('isbn').filter(lambda df: df.shape[0] > 19)\n",
    "print_information(df_20_ratings_least, 'dataframe only books rated more than 20 times')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the purpose of the recommendation system we want to train different models and see which one performs best.\n",
    "The following models will be used\n",
    "- SVD\n",
    "- User Based Collaborative Filtering \n",
    "- Item Based Collaborative Filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in /Users/tolgayasar/opt/anaconda3/lib/python3.8/site-packages (1.1.1)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/tolgayasar/opt/anaconda3/lib/python3.8/site-packages (from scikit-surprise) (1.1.0)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/tolgayasar/opt/anaconda3/lib/python3.8/site-packages (from scikit-surprise) (1.16.0)\r\n",
      "Requirement already satisfied: numpy>=1.11.2 in /Users/tolgayasar/opt/anaconda3/lib/python3.8/site-packages (from scikit-surprise) (1.21.5)\r\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/tolgayasar/opt/anaconda3/lib/python3.8/site-packages (from scikit-surprise) (1.7.3)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install the surprise package\n",
    "%pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/fxpgq_v15qn2fvg77jff1p100000gn/T/ipykernel_24435/1830921147.py:34: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([alg_list[i]], index=['Algorithm']))\n"
     ]
    },
    {
     "data": {
      "text/plain": "                   test_rmse  test_mae  fit_time  test_time\nAlgorithm                                                  \nSVD(n_factors=50)    1.61473  1.250534   3.63672   0.184497",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test_rmse</th>\n      <th>test_mae</th>\n      <th>fit_time</th>\n      <th>test_time</th>\n    </tr>\n    <tr>\n      <th>Algorithm</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>SVD(n_factors=50)</th>\n      <td>1.61473</td>\n      <td>1.250534</td>\n      <td>3.63672</td>\n      <td>0.184497</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD, NMF, KNNBasic, KNNWithMeans, Dataset, Reader, accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "\n",
    "## Load the data into surprise input data format, split into training and testing\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "trainset, testset = train_test_split(df_10_ratings_least[['user_id','isbn','rating']], test_size=0.25, random_state=0)\n",
    "trainset.index = range(len(trainset)) \n",
    "testset.index = range(len(testset))\n",
    "trainset = Dataset.load_from_df(trainset, reader)\n",
    "testset = testset.values.tolist()\n",
    "\n",
    "# Define the models and their hyperparameters \n",
    "sim_option_item = {'name': 'cosine',\n",
    "              'user_based': False  # compute similarities between items\n",
    "               }\n",
    "sim_option_user = {'name': 'pearson',\n",
    "              'user_based': True  # compute similarities between users\n",
    "               }\n",
    "alg_list = ['SVD(n_factors=50)', 'NMF(n_factors=15)',\n",
    "            'KNNBasic(k=20, sim=cosine, item-based)', \n",
    "            'KNNBasic(k=20, sim=pearson, user-based)']\n",
    "\n",
    "i = 0\n",
    "\n",
    "benchmark = []\n",
    "\n",
    "\n",
    "# Iterate over selected algorithms based on 5-fold CV on training set\n",
    "for algorithm in [SVD(n_factors=30), NMF(n_factors=15), KNNBasic(k=20, sim_options=sim_option_item), KNNBasic(k=20, sim_options=sim_option_user)]:\n",
    "    # Perform cross validation\n",
    "    results = cross_validate(algorithm, trainset, measures=['RMSE','MAE'], cv=5, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp.append(pd.Series([alg_list[i]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    i+=1\n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Dimensions: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "test_rmse    1.610759\ntest_mae     1.247307\nfit_time     1.662944\ntest_time    0.171707\ndtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/fxpgq_v15qn2fvg77jff1p100000gn/T/ipykernel_24435/3339071703.py:33: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([alg_list[i]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 10\n"
     ]
    },
    {
     "data": {
      "text/plain": "test_rmse    1.613273\ntest_mae     1.249570\nfit_time     1.918559\ntest_time    0.150474\ndtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/fxpgq_v15qn2fvg77jff1p100000gn/T/ipykernel_24435/3339071703.py:33: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([alg_list[i]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 15\n"
     ]
    },
    {
     "data": {
      "text/plain": "test_rmse    1.613857\ntest_mae     1.249606\nfit_time     2.382491\ntest_time    0.159978\ndtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/fxpgq_v15qn2fvg77jff1p100000gn/T/ipykernel_24435/3339071703.py:33: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([alg_list[i]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 20\n"
     ]
    },
    {
     "data": {
      "text/plain": "test_rmse    1.614546\ntest_mae     1.250449\nfit_time     2.273441\ntest_time    0.149492\ndtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/fxpgq_v15qn2fvg77jff1p100000gn/T/ipykernel_24435/3339071703.py:33: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([alg_list[i]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 25\n"
     ]
    },
    {
     "data": {
      "text/plain": "test_rmse    1.615648\ntest_mae     1.251237\nfit_time     2.570838\ntest_time    0.171872\ndtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/fxpgq_v15qn2fvg77jff1p100000gn/T/ipykernel_24435/3339071703.py:33: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([alg_list[i]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 30\n"
     ]
    },
    {
     "data": {
      "text/plain": "test_rmse    1.613880\ntest_mae     1.250181\nfit_time     3.384465\ntest_time    0.173794\ndtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/fxpgq_v15qn2fvg77jff1p100000gn/T/ipykernel_24435/3339071703.py:33: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([alg_list[i]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 35\n"
     ]
    },
    {
     "data": {
      "text/plain": "test_rmse    1.615349\ntest_mae     1.251364\nfit_time     3.139248\ntest_time    0.191417\ndtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/fxpgq_v15qn2fvg77jff1p100000gn/T/ipykernel_24435/3339071703.py:33: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([alg_list[i]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 40\n"
     ]
    },
    {
     "data": {
      "text/plain": "test_rmse    1.614680\ntest_mae     1.251038\nfit_time     3.278906\ntest_time    0.174232\ndtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/fxpgq_v15qn2fvg77jff1p100000gn/T/ipykernel_24435/3339071703.py:33: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([alg_list[i]], index=['Algorithm']))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions: 45\n"
     ]
    },
    {
     "data": {
      "text/plain": "test_rmse    1.616727\ntest_mae     1.252263\nfit_time     3.518142\ntest_time    0.136461\ndtype: float64"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/fxpgq_v15qn2fvg77jff1p100000gn/T/ipykernel_24435/3339071703.py:33: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  tmp = tmp.append(pd.Series([alg_list[i]], index=['Algorithm']))\n"
     ]
    },
    {
     "data": {
      "text/plain": "           test_rmse  test_mae  fit_time  test_time\nAlgorithm                                          \n            1.610759  1.247307  1.662944   0.171707\n5           1.613273  1.249570  1.918559   0.150474\n10          1.613857  1.249606  2.382491   0.159978\n25          1.613880  1.250181  3.384465   0.173794\n15          1.614546  1.250449  2.273441   0.149492\n35          1.614680  1.251038  3.278906   0.174232\n30          1.615349  1.251364  3.139248   0.191417\n20          1.615648  1.251237  2.570838   0.171872\n40          1.616727  1.252263  3.518142   0.136461",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test_rmse</th>\n      <th>test_mae</th>\n      <th>fit_time</th>\n      <th>test_time</th>\n    </tr>\n    <tr>\n      <th>Algorithm</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th></th>\n      <td>1.610759</td>\n      <td>1.247307</td>\n      <td>1.662944</td>\n      <td>0.171707</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1.613273</td>\n      <td>1.249570</td>\n      <td>1.918559</td>\n      <td>0.150474</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.613857</td>\n      <td>1.249606</td>\n      <td>2.382491</td>\n      <td>0.159978</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>1.613880</td>\n      <td>1.250181</td>\n      <td>3.384465</td>\n      <td>0.173794</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1.614546</td>\n      <td>1.250449</td>\n      <td>2.273441</td>\n      <td>0.149492</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>1.614680</td>\n      <td>1.251038</td>\n      <td>3.278906</td>\n      <td>0.174232</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>1.615349</td>\n      <td>1.251364</td>\n      <td>3.139248</td>\n      <td>0.191417</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1.615648</td>\n      <td>1.251237</td>\n      <td>2.570838</td>\n      <td>0.171872</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>1.616727</td>\n      <td>1.252263</td>\n      <td>3.518142</td>\n      <td>0.136461</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import SVD, NMF, KNNBasic, KNNWithMeans, Dataset, Reader, accuracy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "\n",
    "## Load the data into surprise input data format, split into training and testing\n",
    "reader = Reader(rating_scale=(1, 10))\n",
    "trainset, testset = train_test_split(df_10_ratings_least[['user_id','isbn','rating']], test_size=0.25, random_state=0)\n",
    "trainset.index = range(len(trainset)) \n",
    "testset.index = range(len(testset))\n",
    "trainset = Dataset.load_from_df(trainset, reader)\n",
    "testset = testset.values.tolist()\n",
    "\n",
    "\n",
    "benchmark = []\n",
    "i = 0\n",
    "alg_list = ['']\n",
    "\n",
    "\n",
    "# Iterate over selected algorithms based on 5-fold CV on training set\n",
    "for n in range(5,50,5):#, NMF(n_factors=15), KNNBasic(k=20, sim_options=sim_option_item), KNNBasic(k=20, sim_options=sim_option_user)]:\n",
    "    # Perform cross validation\n",
    "    alg_list.append(str(n))\n",
    "    print(n)\n",
    "    algorithm = SVD(n_factors=n)\n",
    "    results = cross_validate(algorithm, trainset, measures=['RMSE','MAE'], cv=5, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    print(f'Dimensions: {n}')\n",
    "    display(tmp)\n",
    "\n",
    "    tmp = tmp.append(pd.Series([alg_list[i]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    i+=1\n",
    "pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Content Based Filtering"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "              isbn                                         book_title  \\\n0       0195153448                                Classical Mythology   \n1       0002005018                                       Clara Callan   \n2       0060973129                               Decision in Normandy   \n3       0374157065  Flu: The Story of the Great Influenza Pandemic...   \n4       0393045218                             The Mummies of Urumchi   \n...            ...                                                ...   \n271374  0440400988                         There's a Bat in Bunk Five   \n271375  0525447644                            From One to One Hundred   \n271376  006008667X  Lily Dale : The True Story of the Town that Ta...   \n271377  0192126040                        Republic (World's Classics)   \n271378  0767409752  A Guided Tour of Rene Descartes' Meditations o...   \n\n                 book_author  year_of_publication  \\\n0         Mark P. O. Morford                 2002   \n1       Richard Bruce Wright                 2001   \n2               Carlo D'Este                 1991   \n3           Gina Bari Kolata                 1999   \n4            E. J. W. Barber                 1999   \n...                      ...                  ...   \n271374        Paula Danziger                 1988   \n271375            Teri Sloat                 1991   \n271376      Christine Wicker                 2004   \n271377                 Plato                 1996   \n271378   Christopher  Biffle                 2000   \n\n                                               publisher  \\\n0                                Oxford University Press   \n1                                  HarperFlamingo Canada   \n2                                        HarperPerennial   \n3                                   Farrar Straus Giroux   \n4                                 W. W. Norton & Company   \n...                                                  ...   \n271374                   Random House Childrens Pub (Mm)   \n271375                                      Dutton Books   \n271376                                HarperSanFrancisco   \n271377                           Oxford University Press   \n271378  McGraw-Hill Humanities/Social Sciences/Languages   \n\n                                                    img_s  \\\n0       http://images.amazon.com/images/P/0195153448.0...   \n1       http://images.amazon.com/images/P/0002005018.0...   \n2       http://images.amazon.com/images/P/0060973129.0...   \n3       http://images.amazon.com/images/P/0374157065.0...   \n4       http://images.amazon.com/images/P/0393045218.0...   \n...                                                   ...   \n271374  http://images.amazon.com/images/P/0440400988.0...   \n271375  http://images.amazon.com/images/P/0525447644.0...   \n271376  http://images.amazon.com/images/P/006008667X.0...   \n271377  http://images.amazon.com/images/P/0192126040.0...   \n271378  http://images.amazon.com/images/P/0767409752.0...   \n\n                                                    img_m  \\\n0       http://images.amazon.com/images/P/0195153448.0...   \n1       http://images.amazon.com/images/P/0002005018.0...   \n2       http://images.amazon.com/images/P/0060973129.0...   \n3       http://images.amazon.com/images/P/0374157065.0...   \n4       http://images.amazon.com/images/P/0393045218.0...   \n...                                                   ...   \n271374  http://images.amazon.com/images/P/0440400988.0...   \n271375  http://images.amazon.com/images/P/0525447644.0...   \n271376  http://images.amazon.com/images/P/006008667X.0...   \n271377  http://images.amazon.com/images/P/0192126040.0...   \n271378  http://images.amazon.com/images/P/0767409752.0...   \n\n                                                    img_l  \n0       http://images.amazon.com/images/P/0195153448.0...  \n1       http://images.amazon.com/images/P/0002005018.0...  \n2       http://images.amazon.com/images/P/0060973129.0...  \n3       http://images.amazon.com/images/P/0374157065.0...  \n4       http://images.amazon.com/images/P/0393045218.0...  \n...                                                   ...  \n271374  http://images.amazon.com/images/P/0440400988.0...  \n271375  http://images.amazon.com/images/P/0525447644.0...  \n271376  http://images.amazon.com/images/P/006008667X.0...  \n271377  http://images.amazon.com/images/P/0192126040.0...  \n271378  http://images.amazon.com/images/P/0767409752.0...  \n\n[271379 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isbn</th>\n      <th>book_title</th>\n      <th>book_author</th>\n      <th>year_of_publication</th>\n      <th>publisher</th>\n      <th>img_s</th>\n      <th>img_m</th>\n      <th>img_l</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0195153448</td>\n      <td>Classical Mythology</td>\n      <td>Mark P. O. Morford</td>\n      <td>2002</td>\n      <td>Oxford University Press</td>\n      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002005018</td>\n      <td>Clara Callan</td>\n      <td>Richard Bruce Wright</td>\n      <td>2001</td>\n      <td>HarperFlamingo Canada</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0060973129</td>\n      <td>Decision in Normandy</td>\n      <td>Carlo D'Este</td>\n      <td>1991</td>\n      <td>HarperPerennial</td>\n      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0374157065</td>\n      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n      <td>Gina Bari Kolata</td>\n      <td>1999</td>\n      <td>Farrar Straus Giroux</td>\n      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0393045218</td>\n      <td>The Mummies of Urumchi</td>\n      <td>E. J. W. Barber</td>\n      <td>1999</td>\n      <td>W. W. Norton &amp; Company</td>\n      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>271374</th>\n      <td>0440400988</td>\n      <td>There's a Bat in Bunk Five</td>\n      <td>Paula Danziger</td>\n      <td>1988</td>\n      <td>Random House Childrens Pub (Mm)</td>\n      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n      <td>http://images.amazon.com/images/P/0440400988.0...</td>\n    </tr>\n    <tr>\n      <th>271375</th>\n      <td>0525447644</td>\n      <td>From One to One Hundred</td>\n      <td>Teri Sloat</td>\n      <td>1991</td>\n      <td>Dutton Books</td>\n      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n      <td>http://images.amazon.com/images/P/0525447644.0...</td>\n    </tr>\n    <tr>\n      <th>271376</th>\n      <td>006008667X</td>\n      <td>Lily Dale : The True Story of the Town that Ta...</td>\n      <td>Christine Wicker</td>\n      <td>2004</td>\n      <td>HarperSanFrancisco</td>\n      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n      <td>http://images.amazon.com/images/P/006008667X.0...</td>\n    </tr>\n    <tr>\n      <th>271377</th>\n      <td>0192126040</td>\n      <td>Republic (World's Classics)</td>\n      <td>Plato</td>\n      <td>1996</td>\n      <td>Oxford University Press</td>\n      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n      <td>http://images.amazon.com/images/P/0192126040.0...</td>\n    </tr>\n    <tr>\n      <th>271378</th>\n      <td>0767409752</td>\n      <td>A Guided Tour of Rene Descartes' Meditations o...</td>\n      <td>Christopher  Biffle</td>\n      <td>2000</td>\n      <td>McGraw-Hill Humanities/Social Sciences/Languages</td>\n      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n      <td>http://images.amazon.com/images/P/0767409752.0...</td>\n    </tr>\n  </tbody>\n</table>\n<p>271379 rows Ã— 8 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "summaries = df.loc[:,['isbn','Summary']]\n",
    "summaries = summaries.groupby('isbn').first().reset_index()\n",
    "summaries\n",
    "\n",
    "books_w_summary = pd.merge(books, summaries, on='isbn', how='left')\n",
    "books_w_summary = books_w_summary.loc[:, ['isbn','Summary']]\n",
    "#replace occurances of '9' in the summary with NaN\n",
    "books_w_summary['Summary'] = books_w_summary.Summary.apply(lambda x: np.NaN if x == '9' else x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "              isbn                                            Summary\n0       0195153448  Provides an introduction to classical myths pl...\n1       0002005018  In a small town in Canada, Clara Callan reluct...\n2       0060973129  Here, for the first time in paperback, is an o...\n3       0374157065  Describes the great flu epidemic of 1918, an o...\n4       0393045218  A look at the incredibly well-preserved ancien...\n...            ...                                                ...\n271373  0449906736  Drawing on their reporting experience from mor...\n271374  0440400988  On her own for the first time, fourteen-year-o...\n271375  0525447644  Illustrations of people and animals introduce ...\n271376  006008667X  An award-winning and wry journalist captures t...\n271377  0192126040  The central work of one of the West&#39;s grea...\n\n[141967 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>isbn</th>\n      <th>Summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0195153448</td>\n      <td>Provides an introduction to classical myths pl...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0002005018</td>\n      <td>In a small town in Canada, Clara Callan reluct...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0060973129</td>\n      <td>Here, for the first time in paperback, is an o...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0374157065</td>\n      <td>Describes the great flu epidemic of 1918, an o...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0393045218</td>\n      <td>A look at the incredibly well-preserved ancien...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>271373</th>\n      <td>0449906736</td>\n      <td>Drawing on their reporting experience from mor...</td>\n    </tr>\n    <tr>\n      <th>271374</th>\n      <td>0440400988</td>\n      <td>On her own for the first time, fourteen-year-o...</td>\n    </tr>\n    <tr>\n      <th>271375</th>\n      <td>0525447644</td>\n      <td>Illustrations of people and animals introduce ...</td>\n    </tr>\n    <tr>\n      <th>271376</th>\n      <td>006008667X</td>\n      <td>An award-winning and wry journalist captures t...</td>\n    </tr>\n    <tr>\n      <th>271377</th>\n      <td>0192126040</td>\n      <td>The central work of one of the West&amp;#39;s grea...</td>\n    </tr>\n  </tbody>\n</table>\n<p>141967 rows Ã— 2 columns</p>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_w_summary = books_w_summary[books_w_summary['Summary'].notna()]\n",
    "books_w_summary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "frozenset({'a',\n           'about',\n           'above',\n           'across',\n           'after',\n           'afterwards',\n           'again',\n           'against',\n           'all',\n           'almost',\n           'alone',\n           'along',\n           'already',\n           'also',\n           'although',\n           'always',\n           'am',\n           'among',\n           'amongst',\n           'amoungst',\n           'amount',\n           'an',\n           'and',\n           'another',\n           'any',\n           'anyhow',\n           'anyone',\n           'anything',\n           'anyway',\n           'anywhere',\n           'are',\n           'around',\n           'as',\n           'at',\n           'back',\n           'be',\n           'became',\n           'because',\n           'become',\n           'becomes',\n           'becoming',\n           'been',\n           'before',\n           'beforehand',\n           'behind',\n           'being',\n           'below',\n           'beside',\n           'besides',\n           'between',\n           'beyond',\n           'bill',\n           'both',\n           'bottom',\n           'but',\n           'by',\n           'call',\n           'can',\n           'cannot',\n           'cant',\n           'co',\n           'con',\n           'could',\n           'couldnt',\n           'cry',\n           'de',\n           'describe',\n           'detail',\n           'do',\n           'done',\n           'down',\n           'due',\n           'during',\n           'each',\n           'eg',\n           'eight',\n           'either',\n           'eleven',\n           'else',\n           'elsewhere',\n           'empty',\n           'enough',\n           'etc',\n           'even',\n           'ever',\n           'every',\n           'everyone',\n           'everything',\n           'everywhere',\n           'except',\n           'few',\n           'fifteen',\n           'fifty',\n           'fill',\n           'find',\n           'fire',\n           'first',\n           'five',\n           'for',\n           'former',\n           'formerly',\n           'forty',\n           'found',\n           'four',\n           'from',\n           'front',\n           'full',\n           'further',\n           'get',\n           'give',\n           'go',\n           'had',\n           'has',\n           'hasnt',\n           'have',\n           'he',\n           'hence',\n           'her',\n           'here',\n           'hereafter',\n           'hereby',\n           'herein',\n           'hereupon',\n           'hers',\n           'herself',\n           'him',\n           'himself',\n           'his',\n           'how',\n           'however',\n           'hundred',\n           'i',\n           'ie',\n           'if',\n           'in',\n           'inc',\n           'indeed',\n           'interest',\n           'into',\n           'is',\n           'it',\n           'its',\n           'itself',\n           'keep',\n           'last',\n           'latter',\n           'latterly',\n           'least',\n           'less',\n           'ltd',\n           'made',\n           'many',\n           'may',\n           'me',\n           'meanwhile',\n           'might',\n           'mill',\n           'mine',\n           'more',\n           'moreover',\n           'most',\n           'mostly',\n           'move',\n           'much',\n           'must',\n           'my',\n           'myself',\n           'name',\n           'namely',\n           'neither',\n           'never',\n           'nevertheless',\n           'next',\n           'nine',\n           'no',\n           'nobody',\n           'none',\n           'noone',\n           'nor',\n           'not',\n           'nothing',\n           'now',\n           'nowhere',\n           'of',\n           'off',\n           'often',\n           'on',\n           'once',\n           'one',\n           'only',\n           'onto',\n           'or',\n           'other',\n           'others',\n           'otherwise',\n           'our',\n           'ours',\n           'ourselves',\n           'out',\n           'over',\n           'own',\n           'part',\n           'per',\n           'perhaps',\n           'please',\n           'put',\n           'rather',\n           're',\n           'same',\n           'see',\n           'seem',\n           'seemed',\n           'seeming',\n           'seems',\n           'serious',\n           'several',\n           'she',\n           'should',\n           'show',\n           'side',\n           'since',\n           'sincere',\n           'six',\n           'sixty',\n           'so',\n           'some',\n           'somehow',\n           'someone',\n           'something',\n           'sometime',\n           'sometimes',\n           'somewhere',\n           'still',\n           'such',\n           'system',\n           'take',\n           'ten',\n           'than',\n           'that',\n           'the',\n           'their',\n           'them',\n           'themselves',\n           'then',\n           'thence',\n           'there',\n           'thereafter',\n           'thereby',\n           'therefore',\n           'therein',\n           'thereupon',\n           'these',\n           'they',\n           'thick',\n           'thin',\n           'third',\n           'this',\n           'those',\n           'though',\n           'three',\n           'through',\n           'throughout',\n           'thru',\n           'thus',\n           'to',\n           'together',\n           'too',\n           'top',\n           'toward',\n           'towards',\n           'twelve',\n           'twenty',\n           'two',\n           'un',\n           'under',\n           'until',\n           'up',\n           'upon',\n           'us',\n           'very',\n           'via',\n           'was',\n           'we',\n           'well',\n           'were',\n           'what',\n           'whatever',\n           'when',\n           'whence',\n           'whenever',\n           'where',\n           'whereafter',\n           'whereas',\n           'whereby',\n           'wherein',\n           'whereupon',\n           'wherever',\n           'whether',\n           'which',\n           'while',\n           'whither',\n           'who',\n           'whoever',\n           'whole',\n           'whom',\n           'whose',\n           'why',\n           'will',\n           'with',\n           'within',\n           'without',\n           'would',\n           'yet',\n           'you',\n           'your',\n           'yours',\n           'yourself',\n           'yourselves'})"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words='english', use_idf=True)\n",
    "X = vectorizer.fit_transform(books_w_summary['Summary'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "data": {
      "text/plain": "(141967, 110449)"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "X_cos_matrix = cosine_similarity(X,X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "indices = pd.Series(books_w_summary.index, index=books_w_summary['isbn']).drop_duplicates()\n",
    "\n",
    "def get_recommendations(isbn, cosine_similarity, indices):\n",
    "    #Get the index of the book that matches the ISBN\n",
    "    index = indices[isbn]\n",
    "    #Get the pairwise similarity scores\n",
    "    sim_scores = list(enumerate(cosine_similarity[index]))\n",
    "\n",
    "    #Sort the books based on the similarity scores (it's the second element, thus x[1])\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    #Get the score for the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}